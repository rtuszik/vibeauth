# VibeCheck Auth - LLM Configuration
# Rename this file to .env and replace the placeholder values with your actual configuration.

# ========== Model Selection ==========
# Default models for vibecheck - supports any LiteLLM compatible model
# Examples: gpt-4, gpt-3.5-turbo, claude-3-opus-20240229, gemini-pro, command-nightly
DEFAULT_MODEL="gpt-3.5-turbo"
VIBE_CHECK_MODEL="gpt-4-turbo"

# ========== API Keys ==========
# Add API keys for the providers you want to use

# OpenAI
OPENAI_API_KEY="your-openai-api-key-here"

# Anthropic
ANTHROPIC_API_KEY="your-anthropic-api-key-here"

# Google (for Gemini models)
# GOOGLE_API_KEY="your-google-api-key-here"
# GEMINI_API_KEY="your-gemini-api-key-here"

# Cohere
# COHERE_API_KEY="your-cohere-api-key-here"

# Replicate
# REPLICATE_API_KEY="your-replicate-api-key-here"

# Hugging Face
# HUGGINGFACE_API_KEY="your-huggingface-api-key-here"

# Together AI
# TOGETHER_API_KEY="your-together-api-key-here"

# Azure OpenAI
# AZURE_API_KEY="your-azure-api-key-here"
# AZURE_API_BASE="https://your-resource.openai.azure.com/"
# AZURE_API_VERSION="2023-05-15"

# ========== Custom Base URLs (Optional) ==========
# Use these to point to custom API endpoints or proxies

# OPENAI_API_BASE="https://api.openai.com/v1"
# ANTHROPIC_API_BASE="https://api.anthropic.com"
# COHERE_API_BASE="https://api.cohere.ai"
# GEMINI_API_BASE="https://generativelanguage.googleapis.com"

# ========== Advanced Configuration (Optional) ==========

# Enable debug logging to see which models are being used
# DEBUG_MODE="true"

# Custom headers for API requests (JSON format)
# LITELLM_CUSTOM_HEADERS='{"X-Custom-Header": "value"}'

# Request timeout in seconds (default: 30)
# LITELLM_REQUEST_TIMEOUT="60"

# Retry configuration
# LITELLM_MAX_RETRIES="3"
# LITELLM_RETRY_DELAY="1"
